{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression\n",
    "$$ g\\big(x\\big) = \\frac{1}{1 + e^{-(w.x + b)}} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "def logitic_regression(X, w, b):\n",
    "    z = np.dot(X, w) + b\n",
    "    f_wb = sigmoid(z)\n",
    "    return f_wb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cost Function\n",
    "$$ J\\big(w, b\\big) = -\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\big(y^{(i)}log\\big(f_{w, b}(x^{(i)})\\big) + \\big(1 - y^{(i)}\\big)\\big(log\\big(1 - f_{w, b}(x^{(i)})\\big)\\big)  $$\n",
    "Regularized:\n",
    "$$ J\\big(w, b\\big) = -\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\big(y^{(i)}log\\big(f_{w, b}(x^{(i)})\\big) + \\big(1 - y^{(i)}\\big)\\big(log\\big(1 - f_{w, b}(x^{(i)})\\big)\\big) + \\frac{\\lambda}{2m}\\displaystyle\\sum_{j=1}^{n}w_{j}^{2} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def compute_cost_logistic_regression(X, y, w, b, lambda_=1):\n",
    "    m, n = X.shape\n",
    "    f_wb = logitic_regression(X, w, b)\n",
    "    cost = np.sum(y*np.log(f_wb) + (1 - y) * np.log(1 - f_wb))\n",
    "    cost /= -m\n",
    "\n",
    "    cost_reg = (lambda_ / (2 * m)) * np.sum(w ** 2)\n",
    "    total_cost = cost + cost_reg\n",
    "\n",
    "    return total_cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized cost: 2.0543906339569977\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,6)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "w_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,) * 2\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7\n",
    "cost_tmp = compute_cost_logistic_regression(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp)\n",
    "\n",
    "print(\"Regularized cost:\", cost_tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Descent\n",
    "$$ w_{j} = w_{j} - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\big(f_{w,b}\\big(x^{(i)}\\big)-y^{(i)}\\big)x_{j}^{(i)} + \\frac{\\lambda}{m}w_{j} $$\n",
    "$$ b = b - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\big(f_{w,b}\\big(x^{(i)}\\big)-y^{(i)}\\big) $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "def compute_gradient_logistic_regression(X, y, w, b, lambda_):\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros((n, ))\n",
    "    dj_db = 0.\n",
    "    f_wb = logitic_regression(X, w, b)\n",
    "    err = f_wb - y\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += err[i] * X[i, j]\n",
    "\n",
    "    dj_db += np.sum(err)\n",
    "\n",
    "    for j in range(n):\n",
    "        dj_dw[j] += lambda_ * w[j]\n",
    "\n",
    "    dj_db /= m\n",
    "    dj_dw /= m\n",
    "    return dj_dw, dj_db"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.341798994972791\n",
      "Regularized dj_dw:\n",
      " [0.17380012933994293, 0.3200750788156695, 0.10776313396851497]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,3)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "w_tmp = np.random.rand(X_tmp.shape[1])\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7\n",
    "dj_dw_tmp, dj_db_tmp = compute_gradient_logistic_regression(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp)\n",
    "\n",
    "print(f\"dj_db: {dj_db_tmp}\", )\n",
    "print(f\"Regularized dj_dw:\\n {dj_dw_tmp.tolist()}\", )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, alpha, lambda_, num_iters):\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = compute_gradient_logistic_regression(X, y, w, b, lambda_)\n",
    "        w -= alpha * dj_dw\n",
    "        b -= dj_db\n",
    "\n",
    "    return w, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final w: [0.6403681057234213, 0.34577216203443556, 0.54508714113052]\n",
      "Final b:\n",
      " -0.9243437114863322\n"
     ]
    }
   ],
   "source": [
    "num_iters = 10000\n",
    "alpha = 5.0e-5\n",
    "w_final, b_final = gradient_descent(X_tmp, y_tmp, w_tmp, b_tmp, alpha, lambda_tmp, num_iters)\n",
    "print(f\"Final w: {w_final.tolist()}\", )\n",
    "print(f\"Final b:\\n {b_final}\", )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost:\n",
      "0.7098603640827459\n"
     ]
    }
   ],
   "source": [
    "cost_final = compute_cost_logistic_regression(X_tmp, y_tmp, w_final, b_final, lambda_tmp)\n",
    "print(f'Cost:\\n{cost_final}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}